{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 영상 길이 넘는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "person_0 = []\n",
    "person_1 = []\n",
    "person_2 = []\n",
    "person_3 = []\n",
    "person_4 = []\n",
    "\n",
    "data_dir = 'korea_data'\n",
    "data_per = os.listdir(data_dir)\n",
    "for person in data_per:\n",
    "    words_dir= f'{data_dir}/{person}'\n",
    "    Id = os.listdir(words_dir)\n",
    "    for id in Id:\n",
    "        if id == '.DS_Store':\n",
    "            continue\n",
    "        id_dir = f'{data_dir}/{person}/{id}'\n",
    "        num = os.listdir(id_dir)\n",
    "        if len(num) == 3:\n",
    "            num = os.listdir(id_dir)\n",
    "            for n  in num:\n",
    "                words_dir_2 = f'{data_dir}/{person}/{id}/{n}/crop_lip'\n",
    "                frames = os.listdir(words_dir_2)\n",
    "                if frames == '.DS_Store':\n",
    "                    continue\n",
    "                if len(frames) < 5:\n",
    "                    if person == '00':\n",
    "                        person_0.append((id, n))\n",
    "                    elif person == '01':\n",
    "                        person_1.append((id, n))\n",
    "                    elif person == '02':\n",
    "                        person_2.append((id, n))\n",
    "                    elif person == '03':\n",
    "                        person_3.append((id, n))\n",
    "                    else:\n",
    "                        person_4.append((id, n))\n",
    "print(len(person_0),len(person_1),len(person_2),len(person_3),len(person_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 전처리(crop)\n",
    "- 입술 주변을 Detect 후 100x50 pixel crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # initialize the list of (x, y)-coordinates\n",
    "    coords = np.zeros((20, 2), dtype=dtype)\n",
    "    # for only lip landmarks\n",
    "    n = 0\n",
    "    for i in range(48, shape.num_parts):\n",
    "        coords[n] = (shape.part(i).x, shape.part(i).y)\n",
    "        n += 1\n",
    "\n",
    "    # return the list of (x, y)-coordinates\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4117647  0.4        0.43529412 ... 0.3137255  0.24313726 0.21568628]]\n",
      "60000\n",
      "[[0.4        0.3882353  0.42352942 ... 0.3137255  0.24313726 0.23921569]]\n",
      "60000\n",
      "[[0.40784314 0.41960785 0.4509804  ... 0.26666668 0.16862746 0.12941177]]\n",
      "60000\n",
      "[[0.39607844 0.40784314 0.4392157  ... 0.2509804  0.16078432 0.12941177]]\n",
      "60000\n",
      "[[0.39215687 0.39607844 0.43529412 ... 0.30588236 0.21568628 0.18431373]]\n",
      "60000\n",
      "[[0.4392157  0.4509804  0.48235294 ... 0.36078432 0.2627451  0.2       ]]\n",
      "60000\n",
      "[[0.43137255 0.4392157  0.47843137 ... 0.32156864 0.20392157 0.16078432]]\n",
      "60000\n",
      "[[0.44313726 0.44705883 0.4862745  ... 0.27450982 0.19607843 0.15294118]]\n",
      "60000\n",
      "[[0.43529412 0.45490196 0.49019608 ... 0.27058825 0.16470589 0.1254902 ]]\n",
      "60000\n",
      "[[0.4392157  0.46666667 0.5019608  ... 0.25882354 0.15294118 0.11372549]]\n",
      "60000\n",
      "[[0.44313726 0.45882353 0.5019608  ... 0.30980393 0.21176471 0.17254902]]\n",
      "60000\n",
      "[[0.43529412 0.4509804  0.49411765 ... 0.35686275 0.25490198 0.22745098]]\n",
      "60000\n",
      "[[0.45882353 0.46666667 0.5058824  ... 0.32156864 0.23137255 0.2       ]]\n",
      "60000\n",
      "[[0.44313726 0.45882353 0.47843137 ... 0.34117648 0.24313726 0.20392157]]\n",
      "60000\n",
      "[[0.44313726 0.4745098  0.5019608  ... 0.3254902  0.22352941 0.2       ]]\n",
      "60000\n",
      "[[0.81960785 0.7647059  0.8745098  ... 0.0627451  0.06666667 0.05882353]]\n",
      "60000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8f4cb4cfb475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mimg_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                 \u001b[0mface_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[0mlandmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Dataset crop Demo\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") # predict 해주는애            \n",
    "\n",
    "data_dir = 'korea_data'\n",
    "data_per = os.listdir(data_dir)\n",
    "for person in data_per:\n",
    "    for sentence in os.listdir(f'{data_dir}/{person}' ):\n",
    "\n",
    "        if sentence == 'csv' or sentence == 'video' or sentence == '.DS_Store':\n",
    "            continue\n",
    "        for nums in os.listdir(f'{data_dir}/{person}/{sentence}'):\n",
    "            if nums == '.DS_Store':\n",
    "                continue\n",
    "            n = 0\n",
    "            for jpg in os.listdir(f'{data_dir}/{person}/{sentence}/{nums}/image'):\n",
    "                # 3초 안으로\n",
    "                if int(jpg[4]) > 4:\n",
    "                    break\n",
    "                faces = f'{data_dir}/{person}/{sentence}/{nums}/image/{jpg}'\n",
    "                src = cv2.imread(faces, cv2.IMREAD_COLOR)\n",
    "                img_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "                face_detector = detector(img_gray, 1)\n",
    "                for face in face_detector:\n",
    "                    landmarks = predictor(src, face)\n",
    "                    landmarks = shape_to_np(landmarks)\n",
    "                    # select center of mouth\n",
    "                    x_list = [x[0] for x in landmarks]\n",
    "                    y_list = [y[1] for y in landmarks]\n",
    "                    x = sum(x_list)//20\n",
    "                    y = sum(y_list)//20\n",
    "                dst = src[y-50:y+50, x-100:x+100].copy()\n",
    "                # 확인용\n",
    "                #cv2.imshow(\"src\", src)\n",
    "                #cv2.imshow(\"dst\", dst)\n",
    "                #cv2.waitKey()\n",
    "                #cv2.destroyAllWindows()\n",
    "                img_tensor = image.img_to_array(dst) #tensor로 type 변경\n",
    "                img_tensor = img_tensor.flatten() # flatten: 12288 차원\n",
    "                img_tensor /= 255. # scaling \n",
    "                img_tensor = np.expand_dims(img_tensor, axis = 0) # (1, 60000) 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JolpJJang",
   "language": "python",
   "name": "jolpjjang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
