{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 영상 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import models, layers, activations\n",
    "from tensorflow.keras.layers import Conv2D, TimeDistributed, BatchNormalization, MaxPooling2D, Flatten, Bidirectional, Dense,Dropout,Flatten\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # initialize the list of (x, y)-coordinates\n",
    "    coords = np.zeros((20, 2), dtype=dtype)\n",
    "    # for only lip landmarks\n",
    "    n = 0\n",
    "    for i in range(48, shape.num_parts):\n",
    "        coords[n] = (shape.part(i).x, shape.part(i).y)\n",
    "        n += 1\n",
    "\n",
    "    # return the list of (x, y)-coordinates\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rect(shape):\n",
    "    rw = 0\n",
    "    rh = 0\n",
    "    rx = 65535\n",
    "    ry = 65535\n",
    "    for (x,y) in shape:\n",
    "        rw = max(rw,x) # w\n",
    "        rh = max(rh,y) # h\n",
    "        rx = min(rx,x) # x\n",
    "        ry = min(ry,y) # y\n",
    "    return (rx,ry,rw-rx,rh-ry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"data/shape_predictor_68_face_landmarks.dat\") # predict 해주는애       \n",
    "\n",
    "count = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        image = cv2.resize(frame, dsize = (640, 480), interpolation = cv2.INTER_AREA)\n",
    "        img = image.copy()\n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        face_detector = detector(img_gray, 1)\n",
    "        cv2.imshow('frame',image)  \n",
    "        for face in face_detector:\n",
    "            landmarks = predictor(image, face)\n",
    "            landmarks = shape_to_np(landmarks)\n",
    "            # select center of mouth\n",
    "            x_list = [x[0] for x in landmarks]\n",
    "            y_list = [y[1] for y in landmarks]\n",
    "            x = sum(x_list)//20\n",
    "            y = sum(y_list)//20\n",
    "            dst = img[y-50:y+50, x-100:x+100].copy()\n",
    "            img_tensor = img_to_array(dst) #tensor로 type 변경\n",
    "            img_tensor /= 255. # scaling  # (100, 200, 3)\n",
    "            img_tensor = np.expand_dims(img_tensor, axis = 0) #(1, 100, 200, 3)  \n",
    "            # frame 별 묶기\n",
    "            if count == 0:\n",
    "                x_data = img_tensor\n",
    "                count += 1\n",
    "            else:\n",
    "                x_data = np.concatenate((x_data, img_tensor), axis = 0)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100, 200, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input x의 값\n",
    "x_data[:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x_data[:5].reshape(-1,5,100, 200, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 100, 200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 입력 predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNet_LSTM(keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(MobileNet_LSTM, self).__init__()\n",
    "        \n",
    "        self.mobile = TimeDistributed(MobileNet(include_top=False))\n",
    "\n",
    "        #self.mobile = TimeDistributed(MobileNet(#weights='imagenet', include_top=False))\n",
    "\n",
    "        self.bilstm = layers.Bidirectional(layers.LSTM(256), merge_mode='concat')\n",
    "        self.dense = layers.Dense(num_classes, activation='softmax')\n",
    "        self.max = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.dropout = layers.Dropout(0.2)\n",
    "        self.flat= TimeDistributed(Flatten())\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.mobile(x)\n",
    "        x = self.max(x)\n",
    "        x = self.dropout(x)      \n",
    "        x = self.flat(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.bilstm(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "mobilenet = MobileNet_LSTM(num_classes = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x19d84215e20>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobilenet.load_weights('MobileNet_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4536185  0.04459177 0.06290834 0.02096995 0.05442841 0.01368549\n",
      "  0.01450968 0.10172824 0.08157995 0.06460723 0.08737256]]\n"
     ]
    }
   ],
   "source": [
    "answer = mobilenet.predict(data)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['아','안','암','어','오','우','이','임','애','와','외']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아\n"
     ]
    }
   ],
   "source": [
    "sent = words[np.argmax(answer)]\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모든 frame합쳐서 string 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ''\n",
    "total = string + sent\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lip",
   "language": "python",
   "name": "lip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
